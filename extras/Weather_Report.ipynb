{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNb3M99tJC+mdSsr1BApfPN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imvickykumar999/Weather-AI-Agent/blob/main/Weather_Report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Pc65AgPgnLmL"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "def get_weather(city: str) -> dict:\n",
        "    \"\"\"Fetch weather from Open-Meteo (free, no key needed).\"\"\"\n",
        "    try:\n",
        "        # Step 1: Geocode city → lat/lon\n",
        "        geo_resp = requests.get(\n",
        "            \"https://geocoding-api.open-meteo.com/v1/search\",\n",
        "            params={\"name\": city, \"count\": 1, \"language\": \"en\", \"format\": \"json\"},\n",
        "            timeout=10,\n",
        "        )\n",
        "        geo_resp.raise_for_status()\n",
        "        geo_data = geo_resp.json()\n",
        "\n",
        "        if not geo_data.get(\"results\"):\n",
        "            return {\"status\": \"error\", \"error_message\": f\"City '{city}' not found.\"}\n",
        "\n",
        "        lat = geo_data[\"results\"][0][\"latitude\"]\n",
        "        lon = geo_data[\"results\"][0][\"longitude\"]\n",
        "        resolved_name = geo_data[\"results\"][0][\"name\"]\n",
        "        country = geo_data[\"results\"][0].get(\"country\", \"\")\n",
        "\n",
        "        # Step 2: Fetch current weather\n",
        "        weather_resp = requests.get(\n",
        "            \"https://api.open-meteo.com/v1/forecast\",\n",
        "            params={\n",
        "                \"latitude\": lat,\n",
        "                \"longitude\": lon,\n",
        "                \"current_weather\": \"true\",\n",
        "            },\n",
        "            timeout=10,\n",
        "        )\n",
        "        weather_resp.raise_for_status()\n",
        "        weather_data = weather_resp.json()\n",
        "\n",
        "        current = weather_data.get(\"current_weather\", {})\n",
        "        if not current:\n",
        "            return {\"status\": \"error\", \"error_message\": \"No current weather available.\"}\n",
        "\n",
        "        temp = current.get(\"temperature\")\n",
        "        wind = current.get(\"windspeed\")\n",
        "\n",
        "        report = (\n",
        "            f\"The weather in {resolved_name}, {country} is \"\n",
        "            f\"{temp}°C with wind speed {wind} km/h.\"\n",
        "        )\n",
        "        return {\"status\": \"success\", \"report\": report}\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\"status\": \"error\", \"error_message\": str(e)}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_weather(\"Noida\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VF2ZdMUcnaQC",
        "outputId": "bda194e3-d78b-40db-f747-59401893f918"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'status': 'success',\n",
              " 'report': 'The weather in Noida, India is 32.8°C with wind speed 8.9 km/h.'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask==3.0.3 requests==2.32.3 python-dotenv==1.0.1 groq>=0.9.0 litellm>=1.43.0 aiohttp>=3.10.5 google-adk"
      ],
      "metadata": {
        "id": "pPl5ussqoEt_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = userdata.get('GROQ_API_KEY')"
      ],
      "metadata": {
        "id": "wlwiuuJ0pTDv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import litellm\n",
        "except Exception:\n",
        "    litellm = None\n",
        "\n",
        "# dir(litellm)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "cIMgYnmapyVB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import logging\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "logging.basicConfig(level=logging.ERROR)"
      ],
      "metadata": {
        "id": "V-MG5b_3qPGG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    print(get_weather(\"New York\"))\n",
        "    print(get_weather(\"Paris\"))\n",
        "except Exception as e:\n",
        "    print(f\"[WeatherAPI test] Skipped due to: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vzkb1iZJqvNa",
        "outputId": "f8522439-a476-4d17-cf8f-6b422c560f27"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'status': 'success', 'report': 'The weather in New York, United States is 19.1°C with wind speed 16.5 km/h.'}\n",
            "{'status': 'success', 'report': 'The weather in Paris, France is 24.0°C with wind speed 7.4 km/h.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GROQ_PRIMARY = \"groq/llama3-70b-8192\"\n",
        "GROQ_FALLBACKS = [\n",
        "    \"groq/llama3-8b-8192\",\n",
        "    \"groq/mixtral-8x7b-32768\",\n",
        "]\n",
        "\n",
        "# ADK/LiteLlm uses OpenAI-style params; keep outputs short to reduce TPM.\n",
        "DEFAULT_MAX_TOKENS = 256"
      ],
      "metadata": {
        "id": "pCG7Wu2vq1iy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.adk.models.lite_llm import LiteLlm  # Multi-provider\n",
        "\n",
        "def make_groq_model(model_name: str) -> LiteLlm:\n",
        "    return LiteLlm(\n",
        "        model=model_name,\n",
        "        api_key=os.getenv(\"GROQ_API_KEY\"),\n",
        "        # Most OpenAI-compatible providers accept \"max_tokens\"\n",
        "        max_tokens=DEFAULT_MAX_TOKENS,\n",
        "        # you can also add temperature/top_p if you want:\n",
        "        # temperature=0.2,\n",
        "        # top_p=0.9,\n",
        "        # LiteLLM will do its own retrying if configured globally; we handle retries below anyway.\n",
        "    )"
      ],
      "metadata": {
        "id": "NIHPqSHoq_8G"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_groq_model(GROQ_PRIMARY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ve112_1rFY8",
        "outputId": "6a01c7d5-5542-46e4-fe85-7ce9907c35bd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LiteLlm(model='groq/llama3-70b-8192', llm_client=<google.adk.models.lite_llm.LiteLLMClient object at 0x7e9fab8c2550>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.adk.agents import Agent\n",
        "\n",
        "weather_agent = Agent(\n",
        "    name=\"weather_agent_v1\",\n",
        "    model=make_groq_model(GROQ_PRIMARY),\n",
        "    description=\"Provides weather information for specific cities.\",\n",
        "    instruction=(\n",
        "        \"You are a helpful weather assistant. \"\n",
        "        \"When the user asks for the weather in a specific city, \"\n",
        "        \"use the 'get_weather' tool to find the information. \"\n",
        "        \"If the tool returns an error, inform the user politely. \"\n",
        "        \"If the tool is successful, present the weather report clearly. \"\n",
        "        \"Keep responses concise.\"\n",
        "    ),\n",
        "    tools=[get_weather],\n",
        ")\n",
        "\n",
        "print(f\"Agent '{weather_agent.name}' created using model '{GROQ_PRIMARY}'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VSMlBldrQay",
        "outputId": "e1b27365-7850-434f-87d3-3ea2db57f297"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent 'weather_agent_v1' created using model 'groq/llama3-70b-8192'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.adk.sessions import InMemorySessionService\n",
        "\n",
        "APP_NAME = \"weather_tutorial_app\"\n",
        "USER_ID = \"user_1\"\n",
        "SESSION_ID = \"session_001\"  # fixed for simplicity\n",
        "\n",
        "session_service = InMemorySessionService()\n",
        "session_service"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rGyGqU6rkna",
        "outputId": "0adba66b-ac09-4402-b80d-7969027c2a3e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<google.adk.sessions.in_memory_session_service.InMemorySessionService at 0x7e9fa199cc50>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "async def create_session():\n",
        "    session = await session_service.create_session(\n",
        "        app_name=APP_NAME,\n",
        "        user_id=USER_ID,\n",
        "        session_id=SESSION_ID\n",
        "    )\n",
        "    print(f\"Session created: App='{APP_NAME}', User='{USER_ID}', Session='{SESSION_ID}'\")\n",
        "    return session\n",
        "\n",
        "create_session()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUgDoRLIr3T5",
        "outputId": "888a5432-2c5d-44cf-b79b-0285a011e45c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<coroutine object create_session at 0x7e9fa1978e40>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.adk.runners import Runner\n",
        "\n",
        "runner = Runner(\n",
        "    agent=weather_agent,\n",
        "    app_name=APP_NAME,\n",
        "    session_service=session_service\n",
        ")\n",
        "\n",
        "print(f\"Runner created for agent '{runner.agent.name}'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZJ-4eyosAf8",
        "outputId": "f116ad25-a9fc-4f50-ec67-b3b5c017ff43"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Runner created for agent 'weather_agent_v1'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re, asyncio\n",
        "\n",
        "RATE_LIMIT_PATTERN = re.compile(r\"try again in ([\\d.]+)s\", re.IGNORECASE)\n",
        "\n",
        "async def _backoff_sleep(err_msg: str, attempt: int):\n",
        "    \"\"\"\n",
        "    Sleep using server-suggested delay if present, else exponential backoff.\n",
        "    \"\"\"\n",
        "    m = RATE_LIMIT_PATTERN.search(err_msg or \"\")\n",
        "    if m:\n",
        "        delay = float(m.group(1))\n",
        "    else:\n",
        "        delay = min(2 ** attempt, 20)  # cap to avoid long stalls\n",
        "    await asyncio.sleep(delay)"
      ],
      "metadata": {
        "id": "oPFerE-KsMWs"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _is_rate_limit_error(e: Exception) -> bool:\n",
        "    if litellm and isinstance(e, getattr(litellm, \"RateLimitError\", tuple())):\n",
        "        return True\n",
        "    msg = f\"{type(e).__name__}: {e}\"\n",
        "    return \"rate limit\" in msg.lower() or \"rate_limit_exceeded\" in msg.lower()"
      ],
      "metadata": {
        "id": "btGPwT2Fsrnj"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def _swap_model_to_fallback(agent: Agent, used: set) -> bool:\n",
        "    \"\"\"\n",
        "    Switch agent.model to the next fallback model not yet used.\n",
        "    Returns True if swapped, False if none left.\n",
        "    \"\"\"\n",
        "    for cand in GROQ_FALLBACKS:\n",
        "        if cand not in used:\n",
        "            agent.model = make_groq_model(cand)\n",
        "            print(f\"[Model Fallback] Switched to: {cand}\")\n",
        "            used.add(cand)\n",
        "            return True\n",
        "    return False"
      ],
      "metadata": {
        "id": "qHI1NoSHs2UN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.genai import types\n",
        "\n",
        "async def call_agent_async(query: str, runner: Runner, user_id: str, session_id: str):\n",
        "    \"\"\"\n",
        "    Sends a query to the agent with robust rate-limit handling and model fallback.\n",
        "    \"\"\"\n",
        "    print(f\"\\n>>> User Query: {query}\")\n",
        "\n",
        "    # Keep the prompt short to reduce token usage.\n",
        "    content = types.Content(role=\"user\", parts=[types.Part(text=query)])\n",
        "\n",
        "    final_response_text = \"Agent did not produce a final response.\"  # Default\n",
        "    max_attempts = 5\n",
        "    attempted_models = {GROQ_PRIMARY}\n",
        "    attempt = 0\n",
        "\n",
        "    while attempt < max_attempts:\n",
        "        attempt += 1\n",
        "        try:\n",
        "            # IMPORTANT: Trim conversation history to reduce tokens.\n",
        "            # If your ADK Runner uses entire session history by default,\n",
        "            # pass only the new message. (Runner handles context internally.)\n",
        "            async for event in runner.run_async(\n",
        "                user_id=user_id,\n",
        "                session_id=session_id,\n",
        "                new_message=content\n",
        "            ):\n",
        "                if event.is_final_response():\n",
        "                    if getattr(event, \"content\", None) and event.content.parts:\n",
        "                        final_response_text = event.content.parts[0].text\n",
        "                    elif getattr(event, \"actions\", None) and getattr(event.actions, \"escalate\", None):\n",
        "                        final_response_text = f\"Agent escalated: {event.error_message or 'No specific message.'}\"\n",
        "                    break\n",
        "\n",
        "            print(f\"<<< Agent Response: {final_response_text}\")\n",
        "            return  # success\n",
        "\n",
        "        except Exception as e:\n",
        "            msg = f\"{type(e).__name__}: {e}\"\n",
        "            if _is_rate_limit_error(e):\n",
        "                print(f\"[RateLimit] Attempt {attempt}/{max_attempts}: {msg}\")\n",
        "\n",
        "                # 1) first: wait as suggested / backoff\n",
        "                await _backoff_sleep(str(e), attempt)\n",
        "\n",
        "                # 2) then: try fallback model if still failing on next loop\n",
        "                # (swap only once per attempt to keep logic simple)\n",
        "                if await _swap_model_to_fallback(runner.agent, attempted_models):\n",
        "                    continue\n",
        "\n",
        "                # If no fallback left, loop will retry with same model after backoff\n",
        "                continue\n",
        "\n",
        "            # Non-rate-limit error: raise or print friendly message and stop\n",
        "            print(f\"[Error] Unhandled exception: {msg}\")\n",
        "            break\n",
        "\n",
        "    # If we reach here, retries exhausted\n",
        "    print(\"<<< Agent Response: We hit provider limits repeatedly. Please try again shortly or upgrade your Groq tier.\")\n"
      ],
      "metadata": {
        "id": "-WhMjgojs-rD"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def run_conversation():\n",
        "    await create_session()\n",
        "    try:\n",
        "        while True:\n",
        "            try:\n",
        "                user_input = input(\"\\n>>> Enter your query (or 'exit' to quit): \")\n",
        "            except (EOFError, KeyboardInterrupt):\n",
        "                print(\"\\nEnding the conversation.\")\n",
        "                break\n",
        "\n",
        "            if user_input.strip().lower() == \"exit\":\n",
        "                print(\"Ending the conversation.\")\n",
        "                break\n",
        "\n",
        "            await call_agent_async(\n",
        "                user_input.strip(),\n",
        "                runner=runner,\n",
        "                user_id=USER_ID,\n",
        "                session_id=SESSION_ID\n",
        "            )\n",
        "    finally:\n",
        "        # Let any pending SSL/HTTP2 writes flush before the loop shuts down\n",
        "        await asyncio.sleep(0.25)\n"
      ],
      "metadata": {
        "id": "i_jOZxiotPNl"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def main():\n",
        "    # No blanket task-cancelling in Colab/Jupyter (causes recursion errors)\n",
        "    await run_conversation()"
      ],
      "metadata": {
        "id": "Hs29YohFtUsd"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        await main()  # use top-level await in Colab\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpFexj6CtYgm",
        "outputId": "33350044-9faf-42ee-ef14-09c8a46ca6c0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Session created: App='weather_tutorial_app', User='user_1', Session='session_001'\n",
            "\n",
            ">>> Enter your query (or 'exit' to quit): hello, how are you?\n",
            "\n",
            ">>> User Query: hello, how are you?\n",
            "<<< Agent Response: Hello! I'm doing well, thank you for asking. I'm here to help you with any weather-related questions you might have. What city's weather would you like to know about?\n",
            "\n",
            ">>> Enter your query (or 'exit' to quit): what is temperature of noida?\n",
            "\n",
            ">>> User Query: what is temperature of noida?\n",
            "<<< Agent Response: The weather in Noida, India is 32.8°C with wind speed 8.9 km/h.\n",
            "\n",
            ">>> Enter your query (or 'exit' to quit): compare its wind speed with dubai\n",
            "\n",
            ">>> User Query: compare its wind speed with dubai\n",
            "<<< Agent Response: Comparing the wind speeds, I see that Dubai has a wind speed of 20.2 km/h, which is higher than Noida's wind speed of 8.9 km/h.\n",
            "\n",
            ">>> Enter your query (or 'exit' to quit): with that of patna\n",
            "\n",
            ">>> User Query: with that of patna\n",
            "<<< Agent Response: Comparing the wind speeds, I see that Patna has a wind speed of 9.0 km/h, which is slightly higher than Noida's wind speed of 8.9 km/h.\n",
            "\n",
            ">>> Enter your query (or 'exit' to quit): tell me some cities in rajasthan\n",
            "\n",
            ">>> User Query: tell me some cities in rajasthan\n",
            "<<< Agent Response: Here are some cities in Rajasthan, India:\n",
            "\n",
            "1. Jaipur\n",
            "2. Jodhpur\n",
            "3. Udaipur\n",
            "4. Kota\n",
            "5. Ajmer\n",
            "\n",
            ">>> Enter your query (or 'exit' to quit): temp of udaipr\n",
            "\n",
            ">>> User Query: temp of udaipr\n",
            "<<< Agent Response: The temperature in Udaipur, India is 29.0°C with wind speed 10.0 km/h.\n",
            "\n",
            ">>> Enter your query (or 'exit' to quit): okay\n",
            "\n",
            ">>> User Query: okay\n",
            "<<< Agent Response: Let me know if you need the weather information for any other city!\n",
            "\n",
            ">>> Enter your query (or 'exit' to quit): exit\n",
            "Ending the conversation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "afLIIA87tbWL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}